"""
–û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è EDA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
"""
import pandas as pd
import numpy as np
import streamlit as st
import os
import json
from pathlib import Path


def sample_data_for_plotting(df, max_points=None, use_sampling=True):
    """–í—ã–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, –µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π"""
    if df is None or df.empty:
        return df
    
    if not use_sampling:
        return df
    
    if max_points is None:
        max_points = 10000
    
    if len(df) <= max_points:
        return df
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É
    sampled_df = df.sample(n=max_points, random_state=42)
    return sampled_df


def detect_and_fix_shift(df):
    """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–¥–≤–∏–≥–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –∏–∑-–∑–∞ –∑–∞–ø—è—Ç—ã—Ö –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö"""
    if df is None or df.empty:
        return df, False
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
    sample_row = df.iloc[0].astype(str).str.cat(sep=' ')
    has_tabs = '\t' in sample_row
    
    fixed = False
    original_shape = df.shape[1]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ - –µ—Å–ª–∏ –≤ –Ω–∏—Ö —Ç–µ–∫—Å—Ç, –≤–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å —Å–¥–≤–∏–≥
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫, –≤–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∞
    if len(numeric_cols) < df.shape[1] * 0.3:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
        last_cols = df.columns[-5:].tolist()
        for col in last_cols:
            if df[col].dtype == 'object':
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ
                non_numeric = df[col].astype(str).str.contains(r'[^0-9.\-]', na=False, regex=True)
                if non_numeric.sum() > len(df) * 0.1:  # –ë–æ–ª–µ–µ 10% –Ω–µ —á–∏—Å–ª–æ–≤—ã—Ö
                    fixed = True
                    break
    
    # –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Å–¥–≤–∏–≥, –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å
    if fixed or has_tabs:
        return df, False  # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ –¥–æ–±–∞–≤–∏–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
    
    return df, fixed


def fix_data_shift(df):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ –ø–µ—Ä–≤—ã—Ö –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 15 —Å—Ç—Ä–æ–∫–∞—Ö –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–¥–≤–∏–≥–æ–≤"""
    if df is None or df.empty or df.shape[0] < 30:
        return df, False, None
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 15 —Å—Ç—Ä–æ–∫
    first_15 = df.head(15)
    last_15 = df.tail(15)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏ –≤ –ø–µ—Ä–≤—ã—Ö –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
    def get_column_type(series):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–æ–ª–æ–Ω–∫–∏: numeric –∏–ª–∏ text"""
        if series.dtype in [np.int64, np.float64]:
            return 'numeric'
        
        # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ
        numeric_count = pd.to_numeric(series, errors='coerce').notna().sum()
        numeric_ratio = numeric_count / len(series) if len(series) > 0 else 0
        
        if numeric_ratio > 0.7:  # –ë–æ–ª–µ–µ 70% —á–∏—Å–ª–æ–≤—ã—Ö - —Å—á–∏—Ç–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π
            return 'numeric'
        else:
            return 'text'
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
    first_types = {}
    last_types = {}
    
    for col in df.columns:
        first_types[col] = get_column_type(first_15[col])
        last_types[col] = get_column_type(last_15[col])
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    mismatches = []
    for col in df.columns:
        if first_types[col] != last_types[col]:
            mismatches.append({
                'column': col,
                'first_15_type': first_types[col],
                'last_15_type': last_types[col]
            })
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
    if mismatches:
        error_msg = "‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –ø–µ—Ä–≤—ã–º–∏ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏:\n\n"
        for mm in mismatches:
            error_msg += f"- –ö–æ–ª–æ–Ω–∫–∞ '{mm['column']}': –ø–µ—Ä–≤—ã–µ 15 —Å—Ç—Ä–æ–∫ - {mm['first_15_type']}, –ø–æ—Å–ª–µ–¥–Ω–∏–µ 15 —Å—Ç—Ä–æ–∫ - {mm['last_15_type']}\n"
        error_msg += "\n–≠—Ç–æ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Å–¥–≤–∏–≥ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑-–∑–∞ –∑–∞–ø—è—Ç—ã—Ö –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª—è—Ö)."
        return df, False, error_msg
    
    return df, False, None


@st.cache_data
def load_data(uploaded_file, delimiter=None):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–¥–≤–∏–≥–æ–≤"""
    if uploaded_file is not None:
        try:
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
            content = uploaded_file.read().decode('utf-8')
            uploaded_file.seek(0)
            
            # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            if delimiter is None:
                # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–±—É–ª—è—Ü–∏–π –∏ –∑–∞–ø—è—Ç—ã—Ö –≤ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                first_lines = content.split('\n')[:5]
                tab_counts = [line.count('\t') for line in first_lines if line.strip()]
                comma_counts = [line.count(',') for line in first_lines if line.strip()]
                
                avg_tabs = np.mean(tab_counts) if tab_counts else 0
                avg_commas = np.mean(comma_counts) if comma_counts else 0
                
                # –ï—Å–ª–∏ —Ç–∞–±—É–ª—è—Ü–∏–π –±–æ–ª—å—à–µ –∏ –æ–Ω–∏ –±–æ–ª–µ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–±—É–ª—è—Ü–∏—é
                if avg_tabs > avg_commas and avg_tabs > 2:
                    delimiter = '\t'
                elif avg_commas > 2:
                    delimiter = ','
                else:
                    delimiter = '\t'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–∞–±—É–ª—è—Ü–∏—è –¥–ª—è TSV
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            if delimiter == '\t':
                df = pd.read_csv(uploaded_file, sep='\t', encoding='utf-8', on_bad_lines='skip', engine='python')
            else:
                df = pd.read_csv(uploaded_file, sep=delimiter, quotechar='"', encoding='utf-8', on_bad_lines='skip', engine='python')
            
            uploaded_file.seek(0)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å–¥–≤–∏–≥–æ–≤
            df, was_fixed, shift_error = fix_data_shift(df)
            
            return df, shift_error, was_fixed
        except Exception as e:
            try:
                # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                uploaded_file.seek(0)
                if delimiter == '\t':
                    df = pd.read_csv(uploaded_file, sep='\t', encoding='latin-1', on_bad_lines='skip', engine='python')
                else:
                    df = pd.read_csv(uploaded_file, sep=delimiter or ',', encoding='latin-1', on_bad_lines='skip', engine='python')
                uploaded_file.seek(0)
                df, was_fixed, shift_error = fix_data_shift(df)
                return df, shift_error, was_fixed
            except Exception as e2:
                return None, f"{str(e)} / {str(e2)}", False
    return None, None, False


def find_target_column(df, numeric_cols, categorical_cols):
    """–ù–∞—Ö–æ–¥–∏—Ç —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    target_col = None
    for col in df.columns:
        if col.lower() in ['survived', 'target', 'label', 'y', 'class']:
            target_col = col
            break
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –∏–ª–∏ —á–∏—Å–ª–æ–≤–æ–π
    if target_col is None:
        if categorical_cols:
            target_col = categorical_cols[0]
        elif numeric_cols:
            target_col = numeric_cols[0]
    
    return target_col


@st.cache_data
def compute_correlation_matrix(df, numeric_cols):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã"""
    if len(numeric_cols) < 2:
        return None
    return df[numeric_cols].corr()


@st.cache_data
def compute_basic_stats(df, numeric_cols):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    if not numeric_cols:
        return None
    return df[numeric_cols].describe()


@st.cache_data
def compute_value_counts(df, col, top_n=10):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç –∑–Ω–∞—á–µ–Ω–∏–π"""
    return df[col].value_counts().head(top_n)


@st.cache_data
def compute_outliers(df, col):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤"""
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    return Q1, Q3, IQR, lower_bound, upper_bound, outliers


@st.cache_data
def compute_missing_stats(df):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤"""
    missing_data = df.isnull().sum()
    missing_percent = (missing_data / len(df)) * 100
    missing_df = pd.DataFrame({
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': missing_data,
        '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent
    })
    return missing_df[missing_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0].sort_values('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)


# ========== –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° KAGGLE ==========

def get_kaggle_datasets():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
    return {
        'Titanic': {
            'dataset': 'c/titanic',
            'description': '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –æ –ø–∞—Å—Å–∞–∂–∏—Ä–∞—Ö –¢–∏—Ç–∞–Ω–∏–∫–∞ (891 —Å—Ç—Ä–æ–∫–∞, 12 —Å—Ç–æ–ª–±—Ü–æ–≤)',
            'size': '~60 KB',
            'requires_acceptance': True,  # –°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∏–Ω—è—Ç–∏—è –ø—Ä–∞–≤–∏–ª
            'note': '‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –ø—Ä–∞–≤–∏–ª–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è –Ω–∞ Kaggle'
        },
        'House Prices': {
            'dataset': 'c/house-prices-advanced-regression-techniques',
            'description': '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –¥–æ–º–∞ (1460 —Å—Ç—Ä–æ–∫, 81 —Å—Ç–æ–ª–±–µ—Ü)',
            'size': '~300 KB',
            'requires_acceptance': True,  # –°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∏–Ω—è—Ç–∏—è –ø—Ä–∞–≤–∏–ª
            'note': '‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –ø—Ä–∞–≤–∏–ª–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è –Ω–∞ Kaggle'
        },
        'Sales Data': {
            'dataset': 'rohanrao/aisles-and-sales-data',
            'description': '–î–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ 10000+ —Å—Ç—Ä–æ–∫)',
            'size': '~500 KB',
            'requires_acceptance': False,
            'note': None
        },
        'Customer Segmentation': {
            'dataset': 'vjchoudhary7/customer-segmentation-tutorial-in-python',
            'description': '–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞ (2000 —Å—Ç—Ä–æ–∫, 8 —Å—Ç–æ–ª–±—Ü–æ–≤)',
            'size': '~50 KB',
            'requires_acceptance': False,
            'note': None
        },
        'Iris': {
            'dataset': 'uciml/iris',
            'description': '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç Iris –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (150 —Å—Ç—Ä–æ–∫, 5 —Å—Ç–æ–ª–±—Ü–æ–≤)',
            'size': '~5 KB',
            'requires_acceptance': False,
            'note': None
        },
        'Wine Quality': {
            'dataset': 'uciml/red-wine-quality-cortez-et-al-2009',
            'description': '–ö–∞—á–µ—Å—Ç–≤–æ –∫—Ä–∞—Å–Ω–æ–≥–æ –≤–∏–Ω–∞ (1599 —Å—Ç—Ä–æ–∫, 12 —Å—Ç–æ–ª–±—Ü–æ–≤)',
            'size': '~30 KB',
            'requires_acceptance': False,
            'note': None
        }
    }


def setup_kaggle_api(username=None, api_key=None):
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç Kaggle API —Å —É—á–µ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    try:
        kaggle_dir = Path.home() / '.kaggle'
        kaggle_dir.mkdir(exist_ok=True)
        
        kaggle_json = kaggle_dir / 'kaggle.json'
        
        if username and api_key:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            credentials = {
                'username': username,
                'key': api_key
            }
            with open(kaggle_json, 'w') as f:
                json.dump(credentials, f)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è Unix)
            if os.name != 'nt':  # –ù–µ Windows
                os.chmod(kaggle_json, 0o600)
            return True, "‚úÖ Kaggle API –Ω–∞—Å—Ç—Ä–æ–µ–Ω —É—Å–ø–µ—à–Ω–æ!"
        elif kaggle_json.exists():
            # –£—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å
            return True, "‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ Kaggle"
        else:
            return False, "‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å username –∏ API key"
    except Exception as e:
        return False, f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Kaggle API: {str(e)}"


def download_kaggle_dataset(dataset_name, dataset_path):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle"""
    try:
        from kaggle.api.kaggle_api_extended import KaggleApi
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º API
        api = KaggleApi()
        try:
            api.authenticate()
        except Exception as auth_error:
            error_msg = str(auth_error)
            if "401" in error_msg or "Unauthorized" in error_msg:
                return None, "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ username –∏ API key –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Kaggle"
            else:
                return None, f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Kaggle API: {error_msg}"
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        import tempfile
        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —ç—Ç–æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ –∏–ª–∏ –æ–±—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
                if dataset_path.startswith('c/'):
                    # –≠—Ç–æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º competition_download_files
                    competition_name = dataset_path[2:]
                    api.competition_download_files(competition_name, path=temp_dir, unzip=True)
                else:
                    # –û–±—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
                    api.dataset_download_files(dataset_path, path=temp_dir, unzip=True)
            except Exception as download_error:
                error_msg = str(download_error)
                if "403" in error_msg or "Forbidden" in error_msg:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –±–ª–æ–∫–µ except
                    raise download_error
                elif "404" in error_msg or "Not Found" in error_msg:
                    return None, f"–î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_path}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É."
                else:
                    return None, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞: {error_msg}"
            
            # –ò—â–µ–º CSV —Ñ–∞–π–ª—ã –≤ —Å–∫–∞—á–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            csv_files = list(Path(temp_dir).glob('*.csv'))
            
            if not csv_files:
                # –ï—Å–ª–∏ –Ω–µ—Ç CSV –≤ –∫–æ—Ä–Ω–µ, –∏—â–µ–º –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
                csv_files = list(Path(temp_dir).rglob('*.csv'))
            
            if csv_files:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π CSV —Ñ–∞–π–ª (–æ–±—ã—á–Ω–æ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞)
                # –ò–ª–∏ —Ñ–∞–π–ª —Å –∏–º–µ–Ω–µ–º, –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
                main_file = csv_files[0]
                if len(csv_files) > 1:
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª train.csv –∏–ª–∏ —Ñ–∞–π–ª —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞
                    for f in csv_files:
                        if 'train' in f.name.lower() or dataset_name.lower() in f.name.lower():
                            main_file = f
                            break
                
                # –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
                try:
                    df = pd.read_csv(main_file, encoding='utf-8')
                except UnicodeDecodeError:
                    # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                    try:
                        df = pd.read_csv(main_file, encoding='latin-1')
                    except:
                        df = pd.read_csv(main_file, encoding='cp1252')
                
                if df is not None and not df.empty:
                    return df, None
                else:
                    return None, f"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ —Ñ–∞–π–ª {main_file.name} –ø—É—Å—Ç –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω"
            else:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
                all_files = list(Path(temp_dir).rglob('*'))
                file_extensions = [f.suffix for f in all_files if f.is_file()]
                return None, f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ. –ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏: {set(file_extensions)}"
                
    except ImportError:
        return None, "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ kaggle –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install kaggle"
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return None, "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ username –∏ API key –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Kaggle"
        elif "403" in error_msg or "Forbidden" in error_msg:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –ø—Ä–∞–≤–∏–ª
            # –î–ª—è —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π (c/) –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥–æ–π URL
            if dataset_path.startswith('c/'):
                dataset_url = f"https://www.kaggle.com/competitions/{dataset_path[2:]}"
                competition_name = dataset_path[2:]
            else:
                dataset_url = f"https://www.kaggle.com/datasets/{dataset_path}"
                competition_name = None
            
            error_text = (
                f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω. –î–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–Ω—è—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ Kaggle.\n\n"
                f"üìã –ß—Ç–æ –¥–µ–ª–∞—Ç—å:\n"
            )
            
            if competition_name:
                error_text += (
                    f"1. –û—Ç–∫—Ä–æ–π—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è: {dataset_url}\n"
                    f"2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É 'Join Competition' –∏–ª–∏ 'I Understand and Accept'\n"
                    f"3. –ü—Ä–∏–º–∏—Ç–µ –ø—Ä–∞–≤–∏–ª–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è (–æ–±—ã—á–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ email)\n"
                )
            else:
                error_text += (
                    f"1. –û—Ç–∫—Ä–æ–π—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–∞—Ç–∞—Å–µ—Ç–∞: {dataset_url}\n"
                    f"2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É 'I Understand and Accept' –∏–ª–∏ 'Accept Rules'\n"
                )
            
            error_text += (
                f"4. –ü–æ—Å–ª–µ –ø—Ä–∏–Ω—è—Ç–∏—è –ø—Ä–∞–≤–∏–ª –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å–Ω–æ–≤–∞\n\n"
                f"üí° –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤—Ä—É—á–Ω—É—é —Å —Å–∞–π—Ç–∞ Kaggle –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ '–ó–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª'"
            )
            
            return None, error_text
        elif "404" in error_msg or "Not Found" in error_msg:
            return None, f"–î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_path}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É."
        else:
            return None, f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {error_msg}"


# ========== –§–£–ù–ö–¶–ò–ò –î–õ–Ø –≠–ö–°–ü–û–†–¢–ê –û–¢–ß–ï–¢–û–í ==========

def generate_html_report(df, numeric_cols, categorical_cols, target_col, correlation_matrix=None, vif_data=None, hypotheses=None):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"""
    from datetime import datetime
    import base64
    import io
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>EDA –û—Ç—á–µ—Ç - {datetime.now().strftime('%Y-%m-%d %H:%M')}</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                margin: 20px;
                background-color: #f5f5f5;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
                background-color: white;
                padding: 30px;
                box-shadow: 0 0 10px rgba(0,0,0,0.1);
            }}
            h1 {{
                color: #2c3e50;
                border-bottom: 3px solid #3498db;
                padding-bottom: 10px;
            }}
            h2 {{
                color: #34495e;
                margin-top: 30px;
                border-left: 4px solid #3498db;
                padding-left: 10px;
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
            }}
            th, td {{
                border: 1px solid #ddd;
                padding: 12px;
                text-align: left;
            }}
            th {{
                background-color: #3498db;
                color: white;
            }}
            tr:nth-child(even) {{
                background-color: #f2f2f2;
            }}
            .stat-box {{
                background-color: #ecf0f1;
                padding: 15px;
                margin: 10px 0;
                border-radius: 5px;
            }}
            .warning {{
                background-color: #fff3cd;
                border-left: 4px solid #ffc107;
                padding: 10px;
                margin: 10px 0;
            }}
            .success {{
                background-color: #d4edda;
                border-left: 4px solid #28a745;
                padding: 10px;
                margin: 10px 0;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üìä –û—Ç—á–µ—Ç EDA –∞–Ω–∞–ª–∏–∑–∞</h1>
            <p><strong>–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            
            <h2>1. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ</h2>
            <div class="stat-box">
                <p><strong>–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞:</strong> {df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤</p>
                <p><strong>–ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:</strong> {len(numeric_cols)}</p>
                <p><strong>–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:</strong> {len(categorical_cols)}</p>
                <p><strong>–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:</strong> {target_col if target_col else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'}</p>
            </div>
            
            <h2>2. –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è</h2>
            <table>
                <tr>
                    <th>–ü—Ä–∏–∑–Ω–∞–∫</th>
                    <th>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤</th>
                    <th>–ü—Ä–æ—Ü–µ–Ω—Ç</th>
                </tr>
    """
    
    missing_data = df.isnull().sum()
    missing_percent = (missing_data / len(df)) * 100
    for col in df.columns:
        if missing_data[col] > 0:
            html_content += f"""
                <tr>
                    <td>{col}</td>
                    <td>{missing_data[col]}</td>
                    <td>{missing_percent[col]:.2f}%</td>
                </tr>
            """
    
    html_content += """
            </table>
    """
    
    if correlation_matrix is not None:
        html_content += """
            <h2>3. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑</h2>
            <p>–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∞ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.</p>
        """
        
        if vif_data:
            html_content += """
                <h3>3.1. –ê–Ω–∞–ª–∏–∑ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ (VIF)</h3>
                <table>
                    <tr>
                        <th>–ü—Ä–∏–∑–Ω–∞–∫</th>
                        <th>VIF</th>
                        <th>–û—Ü–µ–Ω–∫–∞</th>
                    </tr>
            """
            for vif_row in vif_data:
                html_content += f"""
                    <tr>
                        <td>{vif_row['–ü—Ä–∏–∑–Ω–∞–∫']}</td>
                        <td>{vif_row['VIF']}</td>
                        <td>{vif_row['–û—Ü–µ–Ω–∫–∞']}</td>
                    </tr>
                """
            html_content += """
                </table>
            """
    
    if hypotheses:
        html_content += """
            <h2>4. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã</h2>
        """
        for i, hyp in enumerate(hypotheses, 1):
            html_content += f"""
                <div class="stat-box">
                    <h3>–ì–∏–ø–æ—Ç–µ–∑–∞ {i}: {hyp.get('–ì–∏–ø–æ—Ç–µ–∑–∞', 'N/A')}</h3>
                    <p><strong>–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:</strong> {hyp.get('–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', 'N/A')}</p>
                    <p><strong>–ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏:</strong> {hyp.get('–ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏', 'N/A')}</p>
            """
            if 'statistical_test' in hyp and hyp['statistical_test']:
                html_content += f"<p><strong>–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç:</strong><br>{hyp['statistical_test'].replace(chr(10), '<br>')}</p>"
            html_content += "</div>"
    
    html_content += """
        </div>
    </body>
    </html>
    """
    
    return html_content


def generate_pdf_report(df, numeric_cols, categorical_cols, target_col, correlation_matrix=None, vif_data=None, hypotheses=None):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç PDF –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"""
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib import colors
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_CENTER, TA_LEFT
    from datetime import datetime
    import io
    
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
    
    story = []
    styles = getSampleStyleSheet()
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        textColor=colors.HexColor('#2c3e50'),
        spaceAfter=30,
        alignment=TA_CENTER
    )
    story.append(Paragraph("üìä –û—Ç—á–µ—Ç EDA –∞–Ω–∞–ª–∏–∑–∞", title_style))
    story.append(Paragraph(f"<i>–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</i>", styles['Normal']))
    story.append(Spacer(1, 0.5*inch))
    
    # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    story.append(Paragraph("1. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ", styles['Heading2']))
    info_data = [
        ['–ü–∞—Ä–∞–º–µ—Ç—Ä', '–ó–Ω–∞—á–µ–Ω–∏–µ'],
        ['–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞', f"{df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤"],
        ['–ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', str(len(numeric_cols))],
        ['–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', str(len(categorical_cols))],
        ['–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è', target_col if target_col else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞']
    ]
    info_table = Table(info_data, colWidths=[3*inch, 3*inch])
    info_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#3498db')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    story.append(info_table)
    story.append(Spacer(1, 0.3*inch))
    
    # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    story.append(Paragraph("2. –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", styles['Heading2']))
    missing_data = df.isnull().sum()
    missing_percent = (missing_data / len(df)) * 100
    missing_table_data = [['–ü—Ä–∏–∑–Ω–∞–∫', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤', '–ü—Ä–æ—Ü–µ–Ω—Ç']]
    for col in df.columns:
        if missing_data[col] > 0:
            missing_table_data.append([col, str(missing_data[col]), f"{missing_percent[col]:.2f}%"])
    
    if len(missing_table_data) > 1:
        missing_table = Table(missing_table_data, colWidths=[2.5*inch, 2*inch, 1.5*inch])
        missing_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#3498db')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(missing_table)
    else:
        story.append(Paragraph("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.", styles['Normal']))
    
    story.append(Spacer(1, 0.3*inch))
    
    # VIF –∞–Ω–∞–ª–∏–∑
    if vif_data:
        story.append(Paragraph("3. –ê–Ω–∞–ª–∏–∑ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ (VIF)", styles['Heading2']))
        vif_table_data = [['–ü—Ä–∏–∑–Ω–∞–∫', 'VIF', '–û—Ü–µ–Ω–∫–∞']]
        for vif_row in vif_data:
            vif_table_data.append([vif_row['–ü—Ä–∏–∑–Ω–∞–∫'], vif_row['VIF'], vif_row['–û—Ü–µ–Ω–∫–∞']])
        
        vif_table = Table(vif_table_data, colWidths=[2.5*inch, 1.5*inch, 2*inch])
        vif_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#3498db')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(vif_table)
        story.append(Spacer(1, 0.3*inch))
    
    # –ì–∏–ø–æ—Ç–µ–∑—ã
    if hypotheses:
        story.append(Paragraph("4. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã", styles['Heading2']))
        for i, hyp in enumerate(hypotheses, 1):
            story.append(Paragraph(f"<b>–ì–∏–ø–æ—Ç–µ–∑–∞ {i}:</b> {hyp.get('–ì–∏–ø–æ—Ç–µ–∑–∞', 'N/A')}", styles['Heading3']))
            story.append(Paragraph(f"<b>–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:</b> {hyp.get('–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', 'N/A')}", styles['Normal']))
            story.append(Paragraph(f"<b>–ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏:</b> {hyp.get('–ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏', 'N/A')}", styles['Normal']))
            if 'statistical_test' in hyp and hyp['statistical_test']:
                story.append(Paragraph(f"<b>–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç:</b> {hyp['statistical_test']}", styles['Normal']))
            story.append(Spacer(1, 0.2*inch))
    
    doc.build(story)
    buffer.seek(0)
    return buffer.getvalue()
